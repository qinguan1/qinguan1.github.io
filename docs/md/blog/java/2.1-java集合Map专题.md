## java集合Map专题

作者：qinguan
<br/>博客：[https://bugstack.cn](https://bugstack.cn)

> 故不积跬步，无以至千里；不积小流，无以成江海！🌻

## 一、概述
Map是一种键-值对（key-value）集合，Map集合中的每一个元素都包含一个键对象和一个值对象。
Map接口规定了这类集合的基本雏形，也就是约定了向集合放入元素，从集合取元素，获取集合大小等待一系列方法，以及约定了key-value结构的
元素的接口Entry<K,V>，它的实现类必须实现此接口。
Map接口的实现主要有两类：HashMap类和TreeMap类。其中，HashMap类按哈希算法来存取键对象，而TreeMap类可以对键对象进行排序。

**基于JDK1.8**
## 二、HashMap类

### 2.1 底层数据结构：

HashMap的底层数据在JDK 1.7版本是Table数组 + Entry链表，在JDK1.8版本是 Table数组 + Entry链表/红黑树；(为什么要使用红黑树？)

HashMap结构图：
![HashMap结构图](https://raw.githubusercontent.com/qinguan1/qinguan1.github.io/main/docs/assets/img/qinguan/HashMap结构图.png)

>**小贴士：**
- Java中，TreeMap、TreeSet都使用红黑树作为底层数据结构
- JDK1.8开始，HashMap也引入了红黑树：当冲突的链表长度超过8时，自动转为红黑树
- Linux底层的CFS进程调度算法中，vruntime使用红黑树进行存储。
- 多路复用技术的Epoll，其核心结构是红黑树 + 双向链表。

### 2.2 初始化

什么是负载因子（ loadFactor ）？
我们知道，第一次创建 HashMap 的时候，可以指定其容量（1.7默认容量为16，1.8默认容量为0），那随着我们不断的向 HashMap 
中 put 元素的时候，就有可能会超过其容量，那么就需要有一个扩容机制。如果元素个数（size）超过临界值（threshold）的时候，就会进行自动扩容（resize），并且，在扩容之后，还需要对 HashMap 中原有元素进行 rehash，即将原来桶中的元素重新分配到新的桶中。

**临界值（ threshold ） = 负载因子（ loadFactor ） * 容量（ capacity ）**

HashMap默认的负载因子是0.75

### 2.2 放入元素

hashMap的put源码：

```java
    final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
        // p：表示当前散列表的元素，n：散列表数组的长度，i：寻址的结果
        Node<K,V>[] tab; Node<K,V> p; int n, i;
        // 如果table表未初始化，或者数组长度为0，就会进行扩容操作，并返回扩容后的数组长度
        // resize()扩容方法会开专题讲解
        if ((tab = table) == null || (n = tab.length) == 0)
            n = (tab = resize()).length;
        // 通过取模运算（前文详细写道），来获得寻址结果
        // 也就是传入的key-value键值对在数组中的存储位置    
        if ((p = tab[i = (n - 1) & hash]) == null)
        	// 如果为null，说明此处还没有存储元素，将key-value包装成Node设置在i处
            tab[i] = newNode(hash, key, value, null);
        // else说明寻址结果i已经存储的有元素了，哈希冲突了
        else {
        	// 两个临时变量，node和key
            Node<K,V> e; K k;
            // 表示你要插入的key和原位置的key完全相同，这里将p赋值给e，便于后文的替换操作
            if (p.hash == hash &&
                ((k = p.key) == key || (key != null && key.equals(k))))
                e = p;
            // 此时说明p已经树化，调用红黑树的方法添加到指定位置
            else if (p instanceof TreeNode)
                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
                
            else {// 走到这里说明，hash寻址冲突了，并且和寻址结果i处的key不同，也不是树，说明此时要在链表上操作了
            	// 找到链表的尾节点，插入新节点
                for (int binCount = 0; ; ++binCount) {
                    if ((e = p.next) == null) {
                        p.next = newNode(hash, key, value, null);
                        // 说明此时链表长度超过了树化阈值，进行树化
                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                            treeifyBin(tab, hash);
                        break;
                    }
                    // 此时在链表找尾节点时，发现了和新插入节点完全一致的key，所以记录，跳出，后文替换
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        break;
                    p = e;
                }
            }
            // 替换操作，如果e!=null，说明e记录了冲突的节点
            if (e != null) { // existing mapping for key
            	//记录老值，用于返回
                V oldValue = e.value;
                // 开头传入的参数flase，说明冲突时会进行替换操作
                if (!onlyIfAbsent || oldValue == null)
                    e.value = value;
                // 具体实现在LinkedHashMap，此处不在详解
                afterNodeAccess(e);
                return oldValue;
            }
        }
        //对散列表操作进行记录，用于fast-fail机制
        ++modCount;
        //如果插入后元素超过了扩容阈值，就会进行扩容操作
        if (++size > threshold)
            resize();
        afterNodeInsertion(evict);
        return null;
    }

    /**
    * Replaces all linked nodes in bin at index for given hash unless
    * table is too small, in which case resizes instead.
    * 替换给定哈希表的索引处的所有链表的节点，哈希表太小的情况下，会进行扩容。
    */
    final void treeifyBin(Node<K, V>[] tab, int hash) {
        // 定义n:节点数组长度、index:散列表数组对应的数组下标、e:用于循环的迭代变量,代表当前节点
        int n, index;
        Node<K, V> e;
        // 若散列表数组尚未初始化或者数组长度小于64,则直接扩容而不进行树形化
        if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY)
            resize();
        else if ((e = tab[index = (n - 1) & hash]) != null) {// 获取指定数组下标的头结点e
            // 定义head节点hd、尾节点tl
            TreeNode<K, V> hd = null, tl = null;
            // 循环,该循环主要是将原单向链表转化为双向链表
            do {
                // 以e的hash、key、value,以及以null为后继元创建树形节点p
                TreeNode<K, V> p = replacementTreeNode(e, null);
                // 若尾节点为null表明首次循环,此时e为头结点、p为根节点,因此将p赋值给表示头结点的hd
                if (tl == null)
                    hd = p;
                // 负责根节点已经产生过了此时tl尾节点指向上次循环创建的树形节点
                else {
                    // 此时p为上次循环的的后继元在本次循环为当前节点,产生当前节点与前驱元的prev链
                    p.prev = tl;
                    // 产生前驱元与当前节点的next链
                    tl.next = p;
                }
                // 将tl指向当前节点
                tl = p;
            } while ((e = e.next) != null);// e指向e的后继元素
            // 若指定的位置头结点不为空则进行树形化
            if ((tab[index] = hd) != null)
                // 根据链表创建红黑树结构
                hd.treeify(tab);
        }
    }

```

hashMap的put方法流程图：
![HashMap的put方法流程图](https://raw.githubusercontent.com/qinguan1/qinguan1.github.io/main/docs/assets/img/qinguan/HashMap的put方法流程图.png)

若hash桶中链表元素超过8，散列表数组的长度会自动转化成红黑树
之所以是8，是因为Java的源码贡献者在进行大量实验发现，hash碰撞发生8次的概率已经降低到了0.00000006，几乎为不可能事件，
如果真的碰撞发生了8次，那么这个时候说明由于元素本身和hash函数的原因，此次操作的hash碰撞的可能性非常大了，
后序可能还会继续发生hash碰撞。所以，这个时候，就应该将链表转换为红黑树了，也就是为什么链表转红黑树的阈值是8。 
最后，红黑树转链表的阈值为6，主要是因为，如果也将该阈值设置于8，那么当hash碰撞在8时，会反生链表和红黑树的不停相互激荡转换，白白浪费资源。

### 2.2 扩容

一般情况下，当元素数量超过阈值时便会触发扩容。每次扩容的容量都是之前容量的 2 倍，HashMap 的容量是有上限的，必须小于 1<<30，即 1073741824。如果容量超出了这个范围，则阈值会被设置为 Integer.MAX_VALUE。

扩容机制：

- 空参数的构造函数：实例化的 HashMap 默认内部数组是 null，即没有实例化。第一次调用 put 方法时，则会开始第一次初始化扩容，长度为 16。 
- 有参构造函数：用于指定容量。会根据指定的正整数找到不小于指定容量的 2 的幂数， 将这个数设置赋值给阈值（threshold）。第一次调用 put 方法时，会将阈值赋值给容量， 然后让阈值 = 容量 x 负载因子。 
- 如果不是第一次扩容，则容量变为原来的 2 倍，阈值也变为原来的 2 倍。（容量和阈值 都变为原来的 2 倍时，负载因子还是不变）。 
- 此外还有几个细节需要注意：
    - 首次 put 时，先会触发扩容（算是初始化），然后存入数据，然后判断是否需要扩容； 
    - 不是首次 put，则不再初始化，直接存入数据，然后判断是否需要扩容；

多线程的问题

>**小贴士：**
**在扩容的时候，会对长度小于6的红黑树进行链表的转换。**

### 2.3 散列表的实现

### 2.4 扰动函数

**为什么要用扰动函数？**
- 扰动函数是为了解决集合key的hash碰撞问题

HashMap 源码：
```java

    static final int hash(Object key) {
        int h;
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
    }
```

>问题：
多线程环境下，使用 HashMap 进行put操作会引起死循环，导致CPU利用率接近100%，所以在并发情况下不能使用 HashMap

## 三、Hashtable类

在Java发展的早期就在支持多线程了，所以也提供了一些线程安全的容器，比如在最早JDK1.2提供的集合容器类比如Vector、Hashtable，他们的实现机制都差不多，都是在方法层面上加synchronized关键字来实现线程安全。这种线程安全是以降低性能为代价的，时至今日 Hashtable 它的抽象父类 Dictionary 已被提示为弃用

```java
/**
 * <strong>NOTE: This class is obsolete.  New implementations should
 * implement the Map interface, rather than extending this class.</strong>
 */
 public abstract
class Dictionary<K,V> {
    ...
}
```

所以 **Hashtable 一般是不被推荐使用的。**

## 四、ConcurrentHashMap类

从JDK1.5开始提供了多种并发容器用来改进同步容器的性能，比如用于替代 Hashtable 的同步容器的ConcurrentHashMap。
ConcurrentHashMap 严格来说是线程安全版本的 HashMap，被用来替代 Hashtable ，它的出现解决了 Hashtable 的一些弊端，比如性能低下，这方面主要体现在 Hashtable 的线程安全是基于 synchronized 关键字，早期的 synchronized 锁属于重量级锁，所以对于 Hashtable 而言，每一次对集合的操作都是串行的，它是会锁住整个 hash 表。
JDK1.7中的 ConcurrentHashMap 采用一种更加细粒度的 **“分段锁”** 加锁机制，将整张表分成了多个数组（Segment段），然后每个数组元素又是一个HashMap（hash表），加锁级别只在 Segment 段上，Segment继承了乐观锁ReentrantLock，这就意味着不同的 Segment 段是不会锁冲突的，大大提升了并发性能。
当然了这种方式也有问题，缺点在于分成很多段时会比较浪费内存空间(不连续，碎片化); 操作 Map 时竞争同一个分段锁的概率非常小时，分段锁反而会造成更新等操作的长时间等待; 当某个段很大时，分段锁的性能会下降。
JDK1.8的实现已经摒弃了 Segment 的概念，或者说弱化了 Segment，而是直接用Node数组+链表+红黑树的数据结构来实现，并发控制使用Synchronized 和CAS来操作，这里也涉及到关于 Synchronized 锁的优化，这个在另一个专题会详细讲解。

>**小贴士：为什么不用ReentrantLock而用 synchronized ?** 
>- 减少内存开销：如果使用ReentrantLock则需要节点继承AQS来获得同步支持，增加内存开销，而JDK1.8中只有头节点需要进行同步。
>- Synchronized 则是JVM直接支持的，JVM能够在运行时作出相应的优化措施：锁粗化、锁消除、锁自旋等等。

**ConcurrentHashMap从JDK1.7到JDK1.8的区别汇总：**
- JDK1.8中新增了红黑树，提高了查询效率
- JDK1.7中使用的是头插法，JDK1.8中使用的是尾插法
- JDK1.7中使用了分段锁，而JDK1.8中没有使用分段锁了
- JDK1.7中使用了ReentrantLock，JDK1.8中没有使用ReentrantLock了，而使用了Synchronized
- JDK1.7中的扩容是每个Segment内部进行扩容，不会影响其他Segment，而JDK1.8中的扩容和HashMap的扩容类似，只不过支持了多线程扩容，并且保证了线程安全






## 五、TreeMap类




## 高频面试题部分





















































